
17-12-03 15-20-45
epoch	training_time	train_perf	val_perf
0	498.13745975494385	47.916666666666664	68.75
1	485.4999625682831	47.916666666666664	68.75
2	469.8163366317749	47.916666666666664	68.75
3	417.5468912124634	47.916666666666664	68.75
4	411.35252928733826	47.916666666666664	68.75
5	418.8407709598541	47.916666666666664	68.75
6	417.5639011859894	4.1666666666666625	62.5
7	416.57334995269775	12.5	68.75
8	408.5781419277191	8.333333333333337	62.5
9	401.62099862098694	36.80555555555556	68.75
10	391.8784921169281	2.083333333333337	50.0
11	383.8105401992798	2.777777777777779	50.0
12	396.1574456691742	3.472222222222221	43.75
13	405.80034017562866	0.0	37.5
14	434.8772461414337	3.472222222222221	56.25
15	468.1959185600281	8.333333333333337	56.25
16	412.32383394241333	0.0	31.25
17	374.1481854915619	0.0	31.25
18	402.45520853996277	0.0	12.5
19	362.07661271095276	0.0	12.5
20	362.2531006336212	0.0	12.5
21	362.53339862823486	0.0	18.75
22	362.6679835319519	0.0	37.5
23	362.2372508049011	0.0	12.5
24	371.35180854797363	0.0	43.75

17-12-03 18-32-45
epoch	training_time	train_perf	val_perf

0	416.0487446784973	48.611111111111114	62.5
1	404.38443422317505	48.611111111111114	62.5
2	410.9340031147003	48.611111111111114	62.5
3	425.7032413482666	48.611111111111114	62.5
4	461.0168831348419	48.611111111111114	62.5
5	395.11903738975525	48.611111111111114	62.5
6	379.79260325431824	4.861111111111116	56.25
7	389.1910915374756	15.972222222222221	56.25
8	419.56765246391296	6.944444444444442	56.25
9	419.9505202770233	0.0	18.75
10	436.0757186412811	35.416666666666664	37.5
11	407.3608863353729	4.1666666666666625	50.0
12	409.5642635822296	0.0	31.25
13	401.7388725280762	27.083333333333336	37.5
14	430.2884829044342	1.388888888888884	43.75
15	415.58319878578186	0.694444444444442	43.75
16	383.9856507778168	0.0	18.75
17	372.46555519104004	3.472222222222221	50.0
18	391.59060549736023	0.0	43.75
19	409.8183681964874	0.0	43.75
20	398.04679560661316	0.0	31.25
21	434.47821044921875	0.0	18.75
22	441.6605381965637	0.0	43.75
23	504.77189588546753	0.0	25.0
24	477.9756898880005	0.0	18.75
17-12-04 02-19-58
epoch	training_time	train_perf	val_perf

0	479.5593066215515	26.388888888888886	68.75
1	450.6519615650177	47.22222222222222	62.5
2	448.34854888916016	46.52777777777778	62.5
3	448.58291506767273	47.22222222222222	62.5
4	448.25479197502136	9.722222222222221	62.5
5	449.58293318748474	40.27777777777778	62.5
6	446.9422791004181	0.0	18.75
7	447.214812040329	34.72222222222222	62.5
8	448.11416602134705	4.1666666666666625	37.5
9	445.5516400337219	32.638888888888886	56.25
10	445.2235105037689	8.333333333333337	37.5
11	447.47353196144104	2.777777777777779	50.0
12	446.34852266311646	3.472222222222221	50.0
13	446.53803515434265	0.694444444444442	50.0
14	444.4314317703247	6.944444444444442	37.5
15	446.3952145576477	0.0	43.75
16	447.8797883987427	0.0	37.5
17	445.7078902721405	0.0	37.5
18	446.7199728488922	0.0	37.5
19	449.51048517227173	0.0	37.5
20	448.067289352417	0.0	50.0
21	447.87978982925415	0.0	43.75
22	447.9735383987427	0.0	43.75
23	448.1297914981842	0.0	37.5
24	445.72352147102356	0.0	37.5
17-12-05 01-59-36
epoch	training_time	train_perf	val_perf

0	4.101910352706909	45.175438596491226	51.28205128205128
1	4.051192283630371	45.175438596491226	51.28205128205128
2	4.208540916442871	45.175438596491226	51.28205128205128
3	4.066914319992065	45.175438596491226	51.28205128205128
4	4.49393105506897	45.175438596491226	51.28205128205128
5	4.938007593154907	45.175438596491226	51.28205128205128
6	7.311568975448608	45.175438596491226	51.28205128205128
7	6.023278713226318	45.175438596491226	51.28205128205128
8	5.341501951217651	45.175438596491226	51.28205128205128
9	4.7683868408203125	45.175438596491226	51.28205128205128
10	5.083831787109375	45.175438596491226	51.28205128205128
11	4.871927738189697	45.175438596491226	51.28205128205128
12	4.192504405975342	45.175438596491226	51.28205128205128
13	4.179996728897095	45.175438596491226	51.28205128205128
14	4.169991970062256	45.175438596491226	51.28205128205128
15	4.119462013244629	45.175438596491226	51.28205128205128
16	4.072421073913574	45.175438596491226	51.28205128205128
17	4.1674840450286865	45.175438596491226	51.28205128205128
18	4.535249948501587	44.29824561403509	51.28205128205128
19	4.24956488609314	35.08771929824561	35.89743589743589
20	5.6120216846466064	30.701754385964907	46.15384615384615
21	4.2885754108428955	45.175438596491226	51.28205128205128
22	4.135969877243042	28.947368421052634	38.46153846153846
23	4.179506063461304	43.42105263157895	51.28205128205128
24	4.276568174362183	39.473684210526315	38.46153846153846
17-12-05 02-04-04
epoch	training_time	train_perf	val_perf

0	4.981055736541748	45.175438596491226	51.28205128205128
1	4.932002544403076	45.175438596491226	51.28205128205128
2	4.854489088058472	45.175438596491226	51.28205128205128
3	4.795421600341797	45.175438596491226	51.28205128205128
4	4.86548376083374	45.175438596491226	51.28205128205128
5	4.9154980182647705	45.175438596491226	51.28205128205128
6	4.829467058181763	45.175438596491226	51.28205128205128
7	4.813446044921875	45.175438596491226	51.28205128205128
8	4.847024202346802	45.175438596491226	51.28205128205128
9	4.776456832885742	45.175438596491226	51.28205128205128
10	4.803469657897949	45.175438596491226	51.28205128205128
11	4.781414985656738	45.175438596491226	51.28205128205128
12	4.508285045623779	45.175438596491226	51.28205128205128
13	4.550256252288818	45.175438596491226	51.28205128205128
14	4.488905429840088	45.175438596491226	51.28205128205128
15	4.4869489669799805	45.175438596491226	51.28205128205128
16	4.514235258102417	45.175438596491226	51.28205128205128
17	4.515745401382446	45.175438596491226	51.28205128205128
18	4.467285633087158	44.29824561403509	51.28205128205128
19	4.50324010848999	35.08771929824561	35.89743589743589
20	4.492016553878784	30.701754385964907	46.15384615384615
21	4.472203969955444	45.175438596491226	51.28205128205128
22	4.524171590805054	28.947368421052634	38.46153846153846
23	4.486717939376831	43.42105263157895	51.28205128205128
24	4.509742975234985	39.473684210526315	38.46153846153846
17-12-05 02-09-33
epoch	training_time	train_perf	val_perf

0	9.597816705703735	45.175438596491226	51.28205128205128
1	9.60003137588501	45.175438596491226	51.28205128205128
2	9.429758787155151	45.175438596491226	51.28205128205128
3	9.788123369216919	45.175438596491226	51.28205128205128
4	9.499354362487793	45.175438596491226	51.28205128205128
5	9.652299404144287	45.175438596491226	51.28205128205128
6	9.497924566268921	45.175438596491226	51.28205128205128
7	9.714279890060425	45.175438596491226	51.28205128205128
8	9.501889705657959	45.175438596491226	51.28205128205128
9	9.660968542098999	45.175438596491226	51.28205128205128
10	9.901710987091064	45.175438596491226	51.28205128205128
11	9.456376314163208	45.175438596491226	51.28205128205128
12	9.329784631729126	45.175438596491226	51.28205128205128
13	9.657564163208008	44.73684210526315	51.28205128205128
14	9.41782021522522	45.175438596491226	51.28205128205128
15	9.41779637336731	33.77192982456141	38.46153846153846
16	9.54994797706604	18.42105263157895	30.76923076923077
17	9.457842111587524	45.175438596491226	51.28205128205128
18	9.601824522018433	44.29824561403509	51.28205128205128
19	9.487380266189575	54.824561403508774	48.71794871794872
20	9.48136591911316	16.228070175438592	30.76923076923077
21	9.445889711380005	36.8421052631579	33.333333333333336
22	9.440293550491333	42.54385964912281	43.58974358974359
23	9.56885838508606	44.29824561403509	51.28205128205128
24	9.40424394607544	31.14035087719298	43.58974358974359
17-12-05 02-15-01
epoch	training_time	train_perf	val_perf

0	19.30288076400757	43.94618834080718	56.81818181818181
1	18.571842432022095	43.94618834080718	56.81818181818181
2	18.76651954650879	43.94618834080718	56.81818181818181
3	20.674829959869385	43.94618834080718	56.81818181818181
4	27.171301126480103	43.94618834080718	56.81818181818181
5	22.579278469085693	43.94618834080718	56.81818181818181
6	22.33053731918335	43.94618834080718	56.81818181818181
7	21.875444889068604	43.94618834080718	56.81818181818181
8	21.19123601913452	43.94618834080718	56.81818181818181
9	23.25670313835144	43.94618834080718	56.81818181818181
10	24.432061433792114	43.94618834080718	56.81818181818181
11	23.436359167099	43.94618834080718	56.81818181818181
12	20.25549006462097	43.94618834080718	56.81818181818181
13	23.090622663497925	43.94618834080718	56.81818181818181
14	21.225514888763428	43.94618834080718	56.81818181818181
15	19.167712211608887	43.94618834080718	56.81818181818181
16	19.958376169204712	43.94618834080718	56.81818181818181
17	19.395068407058716	43.94618834080718	56.81818181818181
18	19.61392641067505	29.147982062780265	47.72727272727273
19	19.22275471687317	42.152466367713004	56.81818181818181
20	19.189019441604614	43.94618834080718	56.81818181818181
21	19.38053274154663	8.968609865470857	38.63636363636363
22	22.632063388824463	36.77130044843049	36.36363636363637
23	20.4353346824646	52.46636771300448	36.36363636363637
24	21.490429878234863	36.77130044843049	52.27272727272727
17-12-05 02-25-33
epoch	training_time	train_perf	val_perf

0	37.000476360321045	43.94618834080718	56.81818181818181
1	36.93797469139099	43.94618834080718	56.81818181818181
2	36.92235088348389	43.94618834080718	56.81818181818181
3	36.984846115112305	43.94618834080718	56.81818181818181
4	37.04651880264282	43.94618834080718	56.81818181818181
5	37.17235064506531	43.94618834080718	56.81818181818181
6	37.719237089157104	43.94618834080718	56.81818181818181
7	38.07861256599426	43.94618834080718	56.81818181818181
8	37.03172421455383	43.94618834080718	56.81818181818181
9	37.016101121902466	43.94618834080718	56.81818181818181
10	36.95359945297241	43.94618834080718	56.81818181818181
11	37.10985040664673	43.94618834080718	56.81818181818181
12	37.031723737716675	43.94618834080718	56.81818181818181
13	37.031728744506836	43.94618834080718	56.81818181818181
14	37.03172779083252	28.251121076233186	52.27272727272727
15	36.9536018371582	42.600896860986545	54.54545454545454
16	36.96921706199646	17.9372197309417	31.818181818181824
17	36.95359778404236	22.869955156950674	45.45454545454546
18	37.2348518371582	54.26008968609865	36.36363636363637
19	36.87547302246094	49.775784753363226	36.36363636363637
20	36.85984969139099	47.08520179372198	36.36363636363637
21	36.82859659194946	3.58744394618834	22.72727272727273
22	36.50046753883362	0.8968609865470878	22.72727272727273
23	36.3285915851593	34.97757847533632	54.54545454545454
24	36.266090631484985	0.4484304932735439	31.818181818181824
17-12-05 02-42-23
epoch	training_time	train_perf	val_perf

0	56.31320285797119	43.94618834080718	56.81818181818181
1	56.46947264671326	43.94618834080718	56.81818181818181
2	56.79760408401489	43.94618834080718	56.81818181818181
3	56.391348123550415	43.94618834080718	56.81818181818181
4	56.4226016998291	43.94618834080718	56.81818181818181
5	57.06322956085205	43.94618834080718	56.81818181818181
6	57.250736474990845	43.94618834080718	56.81818181818181
7	57.266358852386475	43.94618834080718	56.81818181818181
8	57.25073480606079	43.94618834080718	56.81818181818181
9	57.23511028289795	43.94618834080718	56.81818181818181
10	57.26635789871216	37.21973094170403	56.81818181818181
11	57.203858852386475	4.0358744394618835	22.72727272727273
12	57.328861474990845	39.9103139013453	54.54545454545454
13	57.172608375549316	24.215246636771305	47.72727272727273
14	57.34449028968811	3.58744394618834	20.45454545454546
15	57.36011004447937	6.726457399103136	29.54545454545454
16	57.375730991363525	1.7937219730941756	25.0
17	57.172609090805054	1.3452914798206317	20.45454545454546
18	57.203858375549316	36.77130044843049	54.54545454545454
19	57.28198575973511	1.7937219730941756	22.72727272727273
20	57.57988142967224	0.0	18.181818181818176
21	57.375736713409424	0.0	18.181818181818176
22	57.250733613967896	0.0	20.45454545454546
23	57.17261028289795	0.0	22.72727272727273
24	57.235108852386475	0.0	20.45454545454546
17-12-05 03-07-36
epoch	training_time	train_perf	val_perf

0	77.48534727096558	43.94618834080718	56.81818181818181
1	77.8134994506836	43.94618834080718	56.81818181818181
2	77.86037468910217	43.94618834080718	56.81818181818181
3	77.84474802017212	43.94618834080718	56.81818181818181
4	77.83832883834839	43.94618834080718	56.81818181818181
5	78.01662635803223	43.94618834080718	56.81818181818181
6	77.70412230491638	43.94618834080718	56.81818181818181
7	77.93849897384644	43.94618834080718	56.81818181818181
8	77.8603744506836	43.94618834080718	56.81818181818181
9	77.81349658966064	43.94618834080718	56.81818181818181
10	77.93850064277649	43.94618834080718	56.81818181818181
11	77.96974992752075	8.968609865470857	34.09090909090909
12	77.92287683486938	4.932735426008971	36.36363636363637
13	77.86037635803223	14.34977578475336	45.45454545454546
14	77.90724539756775	25.11210762331838	47.72727272727273
15	78.09475064277649	2.6905829596412523	31.818181818181824
16	77.86037826538086	5.381165919282516	22.72727272727273
17	77.89162802696228	10.313901345291477	31.818181818181824
18	77.89161920547485	34.08071748878923	52.27272727272727
19	77.86037254333496	0.8968609865470878	25.0
20	77.89162588119507	4.484304932735428	27.27272727272727
21	77.82912111282349	17.040358744394624	36.36363636363637
22	77.12598991394043	0.0	29.54545454545454
23	77.6416220664978	20.17937219730942	38.63636363636363
24	76.7041084766388	0.0	25.0
17-12-05 03-41-26
epoch	training_time	train_perf	val_perf

0	99.5481538772583	43.94618834080718	56.81818181818181
1	102.83903169631958	43.94618834080718	56.81818181818181
2	102.7599401473999	43.94618834080718	56.81818181818181
3	100.4530200958252	43.94618834080718	56.81818181818181
4	100.08879899978638	43.94618834080718	56.81818181818181
5	100.10473036766052	43.94618834080718	56.81818181818181
6	100.21168971061707	43.94618834080718	56.81818181818181
7	100.22922039031982	43.94618834080718	56.81818181818181
8	100.23758792877197	16.59192825112108	43.18181818181818
9	100.25549173355103	18.385650224215244	45.45454545454546
10	100.1754252910614	3.58744394618834	27.27272727272727
11	100.11980533599854	34.52914798206278	27.27272727272727
12	100.03747892379761	13.901345291479817	36.36363636363637
13	100.14069890975952	3.58744394618834	27.27272727272727
14	100.09791707992554	8.968609865470857	22.72727272727273
15	100.24669694900513	5.829596412556048	31.818181818181824
16	100.07565331459045	1.7937219730941756	20.45454545454546
17	100.24118232727051	0.4484304932735439	29.54545454545454
18	100.11146211624146	0.0	20.45454545454546
19	100.2063820362091	0.0	25.0
20	100.11609506607056	1.3452914798206317	31.818181818181824
21	100.38982057571411	25.560538116591925	45.45454545454546
22	100.22003674507141	0.0	29.54545454545454
23	100.11065888404846	0.0	25.0
24	100.24067306518555	0.0	20.45454545454546
17-12-05 04-24-41
epoch	training_time	train_perf	val_perf

0	121.44337224960327	43.94618834080718	56.81818181818181
1	121.61672592163086	43.94618834080718	56.81818181818181
2	121.71836805343628	43.94618834080718	56.81818181818181
3	121.66701412200928	43.94618834080718	56.81818181818181
4	121.69879102706909	43.94618834080718	56.81818181818181
5	121.55381941795349	43.94618834080718	56.81818181818181
6	121.53587627410889	43.94618834080718	56.81818181818181
7	121.57735705375671	43.497757847533634	56.81818181818181
8	121.54403424263	27.802690582959645	50.0
9	121.70122146606445	4.0358744394618835	31.818181818181824
10	121.5299186706543	13.00448430493274	36.36363636363637
11	121.6899025440216	2.6905829596412523	27.27272727272727
12	121.50769567489624	3.58744394618834	22.72727272727273
13	121.4452772140503	41.70403587443946	56.81818181818181
14	121.42674684524536	5.381165919282516	29.54545454545454
15	121.36964654922485	0.8968609865470878	27.27272727272727
16	121.59557437896729	0.4484304932735439	22.72727272727273
17	121.7112991809845	0.4484304932735439	20.45454545454546
18	121.66211700439453	0.8968609865470878	22.72727272727273
19	121.54649496078491	0.0	27.27272727272727
20	121.356454372406	0.0	27.27272727272727
21	121.59856915473938	0.0	18.181818181818176
22	121.54651737213135	0.0	27.27272727272727
23	121.73830246925354	0.0	25.0
24	121.61171531677246	0.0	27.27272727272727

===============================================================================
===============================================================================
===============================================================================

17-12-08 02-21-40
epoch	training_time	train_perf	val_perf

0	7.570384740829468	43.70629370629371	37.66233766233766
1	6.759810924530029	43.70629370629371	37.66233766233766
2	6.596700429916382	43.70629370629371	37.66233766233766
3	6.462598085403442	43.70629370629371	37.66233766233766
4	6.405556678771973	43.70629370629371	37.66233766233766
5	6.404559373855591	43.70629370629371	37.66233766233766
6	6.358522415161133	43.70629370629371	37.66233766233766
7	6.533649206161499	43.70629370629371	37.66233766233766
8	6.6377246379852295	43.70629370629371	37.66233766233766
9	6.400553464889526	43.70629370629371	37.66233766233766
10	6.39354944229126	43.70629370629371	37.66233766233766
11	7.038013696670532	43.70629370629371	37.66233766233766
12	6.3490588665008545	43.70629370629371	37.66233766233766
13	6.542204141616821	43.70629370629371	37.66233766233766
14	6.95051908493042	43.70629370629371	37.66233766233766
15	6.868929862976074	43.70629370629371	37.66233766233766
16	6.326047897338867	23.77622377622378	35.064935064935064
17	6.359076499938965	22.72727272727273	32.467532467532465
18	6.685794830322266	31.818181818181824	33.76623376623377
19	6.406595945358276	39.16083916083915	54.54545454545454
20	6.48464298248291	17.48251748251748	28.57142857142857
21	6.427130460739136	40.20979020979021	36.36363636363637
22	6.2301130294799805	34.96503496503497	53.24675324675325
23	6.348412990570068	11.188811188811187	25.97402597402597
24	6.2965309619903564	17.832167832167833	27.27272727272727
17-12-08 02-27-16
epoch	training_time	train_perf	val_perf

0	15.259377717971802	43.70629370629371	37.66233766233766
1	14.328681707382202	43.70629370629371	37.66233766233766
2	14.11487340927124	43.70629370629371	37.66233766233766
3	14.597001791000366	43.70629370629371	37.66233766233766
4	14.977736711502075	43.70629370629371	37.66233766233766
5	14.120667695999146	43.70629370629371	37.66233766233766
6	14.826699256896973	43.70629370629371	37.66233766233766
7	14.835665702819824	43.70629370629371	37.66233766233766
8	14.107273578643799	43.70629370629371	37.66233766233766
9	14.861485242843628	43.70629370629371	37.66233766233766
10	14.625766515731812	43.70629370629371	37.66233766233766
11	14.781696557998657	43.70629370629371	37.66233766233766
12	14.64647126197815	43.70629370629371	37.66233766233766
13	14.4099280834198	43.70629370629371	37.66233766233766
14	13.99786901473999	43.70629370629371	37.66233766233766
15	14.575268745422363	43.006993006993014	37.66233766233766
16	14.49794316291809	29.72027972027972	44.15584415584416
17	14.597995519638062	36.713286713286706	37.66233766233766
18	14.523567914962769	20.629370629370626	32.467532467532465
19	14.734006643295288	40.20979020979021	37.66233766233766
20	14.692924499511719	40.55944055944056	37.66233766233766
21	14.53834342956543	11.888111888111885	33.76623376623377
22	14.607102870941162	11.538461538461542	35.064935064935064
23	14.663512706756592	5.24475524475524	24.675324675324674
24	15.281026840209961	8.041958041958042	33.76623376623377
17-12-08 02-35-59
epoch	training_time	train_perf	val_perf

0	31.019402980804443	43.70629370629371	37.66233766233766
1	32.04944920539856	43.70629370629371	37.66233766233766
2	27.87539291381836	43.70629370629371	37.66233766233766
3	28.1878981590271	43.70629370629371	37.66233766233766
4	28.094146013259888	43.70629370629371	37.66233766233766
5	28.375401735305786	43.70629370629371	37.66233766233766
6	28.149558782577515	43.70629370629371	37.66233766233766
7	29.75041961669922	43.70629370629371	37.66233766233766
8	30.75043487548828	43.70629370629371	37.66233766233766
9	28.672279357910156	43.70629370629371	37.66233766233766
10	28.750406980514526	43.70629370629371	37.66233766233766
11	29.141034841537476	43.70629370629371	37.66233766233766
12	28.18790078163147	43.70629370629371	37.66233766233766
13	27.937891006469727	43.70629370629371	37.66233766233766
14	27.922269821166992	43.70629370629371	37.66233766233766
15	27.875396013259888	30.76923076923077	31.16883116883117
16	27.87539029121399	24.47552447552448	24.675324675324674
17	27.953519582748413	41.95804195804196	37.66233766233766
18	28.219161987304688	43.70629370629371	51.94805194805194
19	27.89100480079651	20.97902097902098	35.064935064935064
20	27.984771251678467	8.74125874125874	27.27272727272727
21	28.625403881072998	12.23776223776224	28.57142857142857
22	27.828516244888306	9.440559440559436	25.97402597402597
23	27.953519821166992	1.0489510489510523	23.376623376623375
24	27.89101815223694	1.3986013986013957	19.480519480519476
17-12-08 02-49-45
epoch	training_time	train_perf	val_perf

0	56.39141845703125	43.70629370629371	37.66233766233766
1	56.51642036437988	43.70629370629371	37.66233766233766
2	56.328922510147095	43.70629370629371	37.66233766233766
3	56.12579083442688	43.70629370629371	37.66233766233766
4	56.15704131126404	43.70629370629371	37.66233766233766
5	56.14142060279846	43.70629370629371	37.66233766233766
6	56.063292264938354	43.70629370629371	37.66233766233766
7	56.37579154968262	43.70629370629371	37.66233766233766
8	56.39142084121704	43.70629370629371	37.66233766233766
9	56.328924894332886	43.70629370629371	37.66233766233766
10	55.43828058242798	43.70629370629371	37.66233766233766
11	55.48515701293945	43.70629370629371	37.66233766233766
12	55.82891058921814	24.825174825174823	48.05194805194806
13	56.18829393386841	24.825174825174823	27.27272727272727
14	56.4226713180542	39.51048951048951	37.66233766233766
15	56.235169410705566	13.98601398601399	19.480519480519476
16	56.18829321861267	13.98601398601399	20.779220779220775
17	56.42267870903015	5.594405594405593	19.480519480519476
18	56.250783920288086	3.4965034965035002	20.779220779220775
19	56.07891798019409	6.643356643356646	29.87012987012987
20	56.17266631126404	0.6993006993006978	15.58441558441559
21	55.92266488075256	0.34965034965035446	22.077922077922075
22	56.14141821861267	13.98601398601399	28.57142857142857
23	55.95391297340393	0.34965034965035446	19.480519480519476
24	56.860177755355835	0.34965034965035446	19.480519480519476
17-12-08 03-14-57
epoch	training_time	train_perf	val_perf

0	86.7043468952179	43.70629370629371	37.66233766233766
1	86.68872308731079	43.70629370629371	37.66233766233766
2	86.9856026172638	43.70629370629371	37.66233766233766
3	86.89185810089111	43.70629370629371	37.66233766233766
4	86.95434594154358	43.70629370629371	37.66233766233766
5	87.38875770568848	43.70629370629371	37.66233766233766
6	86.8605968952179	43.70629370629371	37.66233766233766
7	87.14185333251953	43.70629370629371	37.66233766233766
8	87.28250336647034	43.70629370629371	37.66233766233766
9	87.01683378219604	43.70629370629371	37.66233766233766
10	86.98559999465942	47.2027972027972	57.14285714285714
11	86.90747690200806	27.97202797202797	33.76623376623377
12	86.95437383651733	35.31468531468531	35.064935064935064
13	86.84495544433594	10.839160839160844	28.57142857142857
14	86.86060643196106	10.139860139860135	18.181818181818176
15	86.98559737205505	13.286713286713292	25.97402597402597
16	86.93873023986816	23.77622377622378	31.16883116883117
17	86.98559713363647	1.7482517482517501	16.883116883116877
18	87.01685500144958	11.538461538461542	25.97402597402597
19	87.42310929298401	2.7972027972028024	24.675324675324674
20	87.0481014251709	0.0	14.28571428571429
21	86.98560237884521	0.6993006993006978	15.58441558441559
22	86.95435523986816	0.0	14.28571428571429
23	86.86059737205505	0.0	14.28571428571429
24	86.9231026172638	0.0	11.688311688311693
17-12-08 03-53-28
epoch	training_time	train_perf	val_perf

0	117.6830542087555	43.70629370629371	37.66233766233766
1	118.1891713142395	43.70629370629371	37.66233766233766
2	119.28840565681458	43.70629370629371	37.66233766233766
3	118.68917512893677	43.70629370629371	37.66233766233766
4	118.40792727470398	43.70629370629371	37.66233766233766
5	117.89228248596191	43.70629370629371	37.66233766233766
6	118.1891679763794	43.70629370629371	37.66233766233766
7	118.26729345321655	38.46153846153846	37.66233766233766
8	118.14229321479797	15.384615384615385	23.376623376623375
9	118.8610532283783	32.86713286713287	32.467532467532465
10	118.42354536056519	10.48951048951049	25.97402597402597
11	118.40792655944824	12.937062937062937	20.779220779220775
12	118.40791535377502	11.188811188811187	24.675324675324674
13	118.51729726791382	20.97902097902098	35.064935064935064
14	118.37667226791382	5.944055944055949	22.077922077922075
15	118.28291773796082	20.629370629370626	37.66233766233766
16	118.49358797073364	0.34965034965035446	14.28571428571429
17	120.33310103416443	0.6993006993006978	10.389610389610393
18	120.34352087974548	0.0	9.090909090909093
19	121.77372765541077	0.0	12.987012987012992
20	118.39045119285583	0.0	15.58441558441559
21	118.39229583740234	0.0	16.883116883116877
22	118.45832300186157	0.0	10.389610389610393
23	118.28291845321655	0.0	12.987012987012992
24	118.50167059898376	0.0	12.987012987012992
17-12-08 04-44-50
epoch	training_time	train_perf	val_perf

0	154.04904913902283	43.70629370629371	37.66233766233766
1	154.44143962860107	43.70629370629371	37.66233766233766
2	153.86154556274414	43.70629370629371	37.66233766233766
3	154.2937684059143	43.70629370629371	37.66233766233766
4	154.29716110229492	43.70629370629371	37.66233766233766
5	154.9802851676941	43.70629370629371	37.66233766233766
6	154.52218174934387	43.70629370629371	37.66233766233766
7	154.90843319892883	43.70629370629371	37.66233766233766
8	154.986558675766	8.391608391608397	23.376623376623375
9	154.51920628547668	31.46853146853147	32.467532467532465
10	154.6442596912384	40.90909090909091	36.36363636363637
11	154.24126863479614	6.99300699300699	19.480519480519476
12	153.80937600135803	13.636363636363635	23.376623376623375
13	155.3032145500183	4.545454545454541	16.883116883116877
14	154.75301003456116	4.545454545454541	20.779220779220775
15	154.5208020210266	1.0489510489510523	18.181818181818176
16	155.2781388759613	0.6993006993006978	14.28571428571429
17	154.56828093528748	0.0	22.077922077922075
18	154.3816909790039	0.0	16.883116883116877
19	154.27408623695374	0.0	19.480519480519476
20	155.14079093933105	0.0	20.779220779220775
21	154.39332723617554	0.0	12.987012987012992
22	155.185955286026	0.0	23.376623376623375
23	154.48826479911804	0.0	22.077922077922075
24	154.25650835037231	0.0	16.883116883116877
17-12-08 05-51-05
epoch	training_time	train_perf	val_perf

0	186.09871077537537	43.70629370629371	37.66233766233766
1	186.27538228034973	43.70629370629371	37.66233766233766
2	186.80861520767212	43.70629370629371	37.66233766233766
3	186.73425912857056	43.70629370629371	37.66233766233766
4	186.2617437839508	43.70629370629371	37.66233766233766
5	186.38480353355408	43.70629370629371	37.66233766233766
6	186.36376786231995	43.70629370629371	37.66233766233766
7	186.05203700065613	41.95804195804196	37.66233766233766
8	186.21152353286743	38.11188811188811	35.064935064935064
9	186.31451272964478	34.61538461538461	33.76623376623377
10	186.25289487838745	18.881118881118887	31.16883116883117
11	186.6318440437317	22.72727272727273	33.76623376623377
12	186.37404251098633	2.7972027972028024	24.675324675324674
13	186.0048794746399	2.447552447552448	15.58441558441559
14	186.19134283065796	0.34965034965035446	15.58441558441559
15	186.09021925926208	7.692307692307687	23.376623376623375
16	187.0065517425537	0.0	14.28571428571429
17	185.965891122818	0.0	15.58441558441559
18	186.24665570259094	0.0	18.181818181818176
19	186.5448296070099	0.0	16.883116883116877
20	186.20403337478638	0.0	15.58441558441559
21	187.11767506599426	0.0	16.883116883116877
22	186.83549618721008	0.0	14.28571428571429
23	186.42206168174744	0.0	18.181818181818176
24	186.73530626296997	0.0	18.181818181818176

===============================================================================


17-12-08 08-13-02
epoch	training_time	train_perf	val_perf

0	48.5475537776947	43.70629370629371	37.66233766233766
1	49.07421088218689	43.70629370629371	37.66233766233766
2	47.500670433044434	43.70629370629371	37.66233766233766
3	47.07879018783569	43.70629370629371	37.66233766233766
4	47.28600263595581	43.70629370629371	37.66233766233766
5	47.478233337402344	43.70629370629371	37.66233766233766
6	49.03585767745972	43.70629370629371	37.66233766233766
7	49.305811166763306	43.70629370629371	37.66233766233766
8	48.112590312957764	43.70629370629371	37.66233766233766
9	47.544734716415405	43.70629370629371	37.66233766233766
10	48.602681398391724	40.55944055944056	37.66233766233766
11	60.38740801811218	15.73426573426573	23.376623376623375
12	55.63480544090271	16.78321678321678	23.376623376623375
13	50.14391493797302	14.685314685314687	33.76623376623377
14	53.61662173271179	4.1958041958041985	18.181818181818176
15	52.88651251792908	18.181818181818176	27.27272727272727
16	50.71740365028381	7.692307692307687	32.467532467532465
17	47.96722197532654	1.3986013986013957	16.883116883116877
18	47.57649254798889	2.0979020979020935	24.675324675324674
19	47.20205736160278	0.34965034965035446	16.883116883116877
20	47.56726598739624	0.34965034965035446	16.883116883116877
21	51.7415235042572	0.0	15.58441558441559
22	51.69725561141968	0.0	18.181818181818176
23	50.19328832626343	0.0	18.181818181818176
24	50.9381742477417	0.0	16.883116883116877
17-12-08 08-37-35
epoch	training_time	train_perf	val_perf

0	52.66840958595276	43.70629370629371	37.66233766233766
1	54.92903780937195	43.70629370629371	37.66233766233766
2	51.93140959739685	43.70629370629371	37.66233766233766
3	52.608521938323975	43.70629370629371	37.66233766233766
4	55.55761194229126	43.70629370629371	37.66233766233766
5	56.093472719192505	43.70629370629371	37.66233766233766
6	56.45467948913574	43.70629370629371	37.66233766233766
7	55.569894313812256	43.70629370629371	37.66233766233766
8	55.111599922180176	41.95804195804196	37.66233766233766
9	51.289533376693726	40.55944055944056	37.66233766233766
10	55.37657284736633	43.006993006993014	37.66233766233766
11	53.045631647109985	13.636363636363635	27.27272727272727
12	52.89559483528137	5.24475524475524	18.181818181818176
13	53.532503843307495	6.643356643356646	19.480519480519476
14	52.27633500099182	3.4965034965035002	19.480519480519476
15	53.94016671180725	0.34965034965035446	23.376623376623375
16	62.2601158618927	2.0979020979020935	19.480519480519476
17	60.12184476852417	39.86013986013987	37.66233766233766
18	54.32425904273987	0.0	15.58441558441559
19	53.44509434700012	0.0	23.376623376623375
20	52.7308988571167	5.944055944055949	28.57142857142857
21	52.05306029319763	0.0	18.181818181818176
22	53.44500470161438	0.0	20.779220779220775
23	51.96997904777527	0.0	20.779220779220775
24	53.589446783065796	0.0	18.181818181818176
17-12-08 09-01-51
epoch	training_time	train_perf	val_perf

0	57.35942268371582	43.70629370629371	37.66233766233766
1	59.34239649772644	43.70629370629371	37.66233766233766
2	58.947498083114624	43.70629370629371	37.66233766233766
3	57.21729230880737	43.70629370629371	37.66233766233766
4	59.364572048187256	43.70629370629371	37.66233766233766
5	61.07406949996948	43.70629370629371	37.66233766233766
6	60.57273530960083	43.70629370629371	37.66233766233766
7	61.26658535003662	19.23076923076923	24.675324675324674
8	60.93269157409668	38.46153846153846	37.66233766233766
9	60.21076011657715	13.286713286713292	22.077922077922075
10	61.48478055000305	14.685314685314687	23.376623376623375
11	60.34962439537048	10.139860139860135	24.675324675324674
12	57.902934551239014	37.06293706293706	51.94805194805194
13	58.76079964637756	8.041958041958042	23.376623376623375
14	69.79512214660645	6.2937062937062915	23.376623376623375
15	66.98140072822571	2.0979020979020935	22.077922077922075
16	75.45815992355347	5.594405594405593	40.25974025974026
17	63.828542709350586	0.6993006993006978	22.077922077922075
18	61.83319687843323	0.34965034965035446	20.779220779220775
19	56.877373933792114	0.0	23.376623376623375
20	56.91977882385254	0.0	24.675324675324674
21	57.362309217453	0.0	15.58441558441559
22	57.231204986572266	0.0	24.675324675324674
23	57.195619106292725	0.0	20.779220779220775
24	58.014554500579834	0.0	22.077922077922075
17-12-08 09-29-31
epoch	training_time	train_perf	val_perf

0	55.22759127616882	43.70629370629371	37.66233766233766
1	55.39729046821594	43.70629370629371	37.66233766233766
2	55.449081897735596	43.70629370629371	37.66233766233766
3	55.5563805103302	43.70629370629371	37.66233766233766
4	55.87875533103943	43.70629370629371	37.66233766233766
5	56.119932651519775	43.70629370629371	37.66233766233766
6	55.7984356880188	43.70629370629371	37.66233766233766
7	55.85043287277222	43.70629370629371	37.66233766233766
8	76.8933277130127	43.70629370629371	37.66233766233766
9	62.091450929641724	43.70629370629371	37.66233766233766
10	56.076682806015015	43.70629370629371	37.66233766233766
11	62.532145977020264	43.70629370629371	37.66233766233766
12	61.782658100128174	24.825174825174823	48.05194805194806
13	71.34375405311584	24.825174825174823	27.27272727272727
14	65.77274894714355	39.51048951048951	37.66233766233766
15	60.80626344680786	13.98601398601399	19.480519480519476
16	66.71818923950195	13.98601398601399	20.779220779220775
17	74.65706181526184	5.594405594405593	19.480519480519476
18	75.79063534736633	3.4965034965035002	20.779220779220775
19	71.78241443634033	6.643356643356646	29.87012987012987
20	62.98647451400757	0.6993006993006978	15.58441558441559
21	64.92332696914673	0.34965034965035446	22.077922077922075
22	66.32645583152771	13.98601398601399	28.57142857142857
23	64.86380124092102	0.34965034965035446	19.480519480519476
24	60.446128845214844	0.34965034965035446	19.480519480519476
17-12-08 09-59-37
epoch	training_time	train_perf	val_perf

0	62.60352063179016	43.70629370629371	37.66233766233766
1	70.69527983665466	43.70629370629371	37.66233766233766
2	62.85207557678223	43.70629370629371	37.66233766233766
3	64.58356738090515	43.70629370629371	37.66233766233766
4	62.43211221694946	43.70629370629371	37.66233766233766
5	68.41769027709961	43.70629370629371	37.66233766233766
6	71.43426156044006	43.70629370629371	37.66233766233766
7	67.84130382537842	43.70629370629371	37.66233766233766
8	69.38849353790283	43.70629370629371	37.66233766233766
9	68.73112535476685	43.70629370629371	37.66233766233766
10	66.35871458053589	43.70629370629371	37.66233766233766
11	67.3970136642456	14.685314685314687	38.961038961038966
12	74.3223066329956	41.25874125874126	37.66233766233766
13	70.82966899871826	28.671328671328666	51.94805194805194
14	70.9664659500122	12.23776223776224	18.181818181818176
15	73.6888313293457	9.790209790209792	19.480519480519476
16	72.4652578830719	10.139860139860135	20.779220779220775
17	67.99133682250977	31.818181818181824	32.467532467532465
18	69.38813400268555	4.1958041958041985	18.181818181818176
19	84.75278043746948	24.125874125874127	50.64935064935065
20	73.64168381690979	4.895104895104896	20.779220779220775
21	87.57258176803589	9.440559440559436	27.27272727272727
22	87.89080691337585	2.0979020979020935	24.675324675324674
23	72.44132471084595	0.0	22.077922077922075
24	68.13282489776611	0.0	15.58441558441559

===============================================================================
===============================================================================
===============================================================================
===============================================================================

17-12-08 14-08-55
epoch	training_time	train_perf	val_perf

0	33.05186605453491	43.70629370629371	37.66233766233766
1	27.87375545501709	43.70629370629371	37.66233766233766
2	28.571677684783936	43.70629370629371	37.66233766233766
3	31.426647424697876	43.70629370629371	37.66233766233766
4	35.88457441329956	43.70629370629371	37.66233766233766
5	40.587297677993774	43.70629370629371	37.66233766233766
6	34.76239275932312	43.70629370629371	37.66233766233766
7	33.46950554847717	43.70629370629371	37.66233766233766
8	29.215542793273926	43.70629370629371	37.66233766233766
9	27.736122131347656	43.70629370629371	37.66233766233766
10	31.39008069038391	43.70629370629371	37.66233766233766
11	28.275768756866455	43.70629370629371	37.66233766233766
12	28.332457065582275	43.70629370629371	37.66233766233766
13	27.221623420715332	43.70629370629371	37.66233766233766
14	31.94759964942932	43.70629370629371	37.66233766233766
15	30.165011405944824	30.76923076923077	31.16883116883117
16	27.459110498428345	24.47552447552448	24.675324675324674
17	33.81024169921875	41.95804195804196	37.66233766233766
18	31.196143627166748	43.70629370629371	51.94805194805194
19	29.759221076965332	20.97902097902098	35.064935064935064
20	27.705026626586914	8.74125874125874	27.27272727272727
21	29.74522352218628	12.23776223776224	28.57142857142857
22	31.564122676849365	9.440559440559436	25.97402597402597
23	33.553366899490356	1.0489510489510523	23.376623376623375
24	32.5587522983551	1.3986013986013957	19.480519480519476
25	31.376271963119507	0.0	18.181818181818176
26	33.289629220962524	0.34965034965035446	24.675324675324674
27	30.6907856464386	0.0	20.779220779220775
28	28.592769861221313	0.0	18.181818181818176
29	29.50994873046875	0.0	19.480519480519476
30	29.26076889038086	0.0	18.181818181818176
31	29.387709856033325	0.0	18.181818181818176
32	29.005337238311768	0.0	19.480519480519476
33	28.30263638496399	0.0	16.883116883116877
34	28.850091218948364	0.0	19.480519480519476
35	28.83908176422119	0.0	16.883116883116877
36	28.232351064682007	0.0	18.181818181818176
37	27.975895404815674	0.0	19.480519480519476
38	27.629042863845825	0.0	15.58441558441559
39	28.79695224761963	0.0	19.480519480519476
17-12-08 14-31-37
epoch	training_time	train_perf	val_perf

0	57.89258670806885	43.70629370629371	37.66233766233766
1	57.56593632698059	43.70629370629371	37.66233766233766
2	56.53520059585571	43.70629370629371	37.66233766233766
3	61.616252422332764	43.70629370629371	37.66233766233766
4	68.66606211662292	43.70629370629371	37.66233766233766
5	66.05421590805054	43.70629370629371	37.66233766233766
6	56.589174032211304	43.70629370629371	37.66233766233766
7	57.538389444351196	43.70629370629371	37.66233766233766
8	57.8163206577301	43.70629370629371	37.66233766233766
9	56.57417607307434	43.70629370629371	37.66233766233766
10	59.56487059593201	43.70629370629371	37.66233766233766
11	58.0484082698822	43.70629370629371	37.66233766233766
12	63.85872483253479	24.825174825174823	48.05194805194806
13	55.9454619884491	24.825174825174823	27.27272727272727
14	55.823238134384155	39.51048951048951	37.66233766233766
15	55.36006164550781	13.98601398601399	19.480519480519476
16	55.39131236076355	13.98601398601399	20.779220779220775
17	55.36006188392639	5.594405594405593	19.480519480519476
18	69.04490399360657	3.4965034965035002	20.779220779220775
19	83.04357695579529	6.643356643356646	29.87012987012987
20	58.427135944366455	0.6993006993006978	15.58441558441559
21	55.537699937820435	0.34965034965035446	22.077922077922075
22	55.6856906414032	13.98601398601399	28.57142857142857
23	55.62572264671326	0.34965034965035446	19.480519480519476
24	56.20162844657898	0.34965034965035446	19.480519480519476
25	55.58811902999878	0.34965034965035446	14.28571428571429
26	55.18508696556091	0.34965034965035446	16.883116883116877
27	55.21943664550781	0.34965034965035446	16.883116883116877
28	55.87569570541382	0.0	16.883116883116877
29	57.920852184295654	0.0	16.883116883116877
30	62.027801275253296	0.0	14.28571428571429
31	70.41667151451111	0.0	14.28571428571429
32	68.92658376693726	0.0	18.181818181818176
33	65.04915475845337	0.0	14.28571428571429
34	56.673663854599	0.0	15.58441558441559
35	66.17595052719116	0.0	14.28571428571429
36	67.09287142753601	0.0	14.28571428571429
37	63.461389780044556	0.0	14.28571428571429
38	61.777230978012085	0.0	12.987012987012992
39	64.49602603912354	0.0	14.28571428571429
17-12-08 15-15-32
epoch	training_time	train_perf	val_perf

0	101.12242889404297	43.70629370629371	37.66233766233766
1	108.87115693092346	43.70629370629371	37.66233766233766
2	103.14037942886353	43.70629370629371	37.66233766233766
3	104.94929957389832	43.70629370629371	37.66233766233766
4	103.48040986061096	43.70629370629371	37.66233766233766
5	106.08756923675537	43.70629370629371	37.66233766233766
6	89.11280059814453	43.70629370629371	37.66233766233766
7	113.07813906669617	43.70629370629371	37.66233766233766
8	96.67942714691162	43.70629370629371	37.66233766233766
9	86.64429378509521	43.70629370629371	37.66233766233766
10	87.40335202217102	47.2027972027972	57.14285714285714
11	87.05549621582031	27.97202797202797	33.76623376623377
12	87.49862241744995	35.31468531468531	35.064935064935064
13	91.48393487930298	10.839160839160844	28.57142857142857
14	106.03949189186096	10.139860139860135	18.181818181818176
15	88.94664788246155	13.286713286713292	25.97402597402597
16	92.23759937286377	23.77622377622378	31.16883116883117
17	83.01179385185242	1.7482517482517501	16.883116883116877
18	622.8209803104401	11.538461538461542	25.97402597402597
19	84.4923346042633	2.7972027972028024	24.675324675324674
20	84.21234107017517	0.0	14.28571428571429
21	84.12262439727783	0.6993006993006978	15.58441558441559
22	86.82290577888489	0.0	14.28571428571429
23	86.43244791030884	0.0	14.28571428571429
24	86.6751503944397	0.0	11.688311688311693
25	86.58057737350464	0.0	11.688311688311693
26	86.32934498786926	0.0	12.987012987012992
27	133.8431429862976	0.0	11.688311688311693
28	86.35888314247131	0.0	15.58441558441559
29	84.32921695709229	0.0	12.987012987012992
30	85.94748449325562	0.0	15.58441558441559
31	86.70323944091797	0.0	12.987012987012992
32	86.79988145828247	0.0	11.688311688311693
33	86.82591462135315	0.34965034965035446	12.987012987012992
34	86.71311283111572	0.0	16.883116883116877
35	85.53720474243164	0.0	15.58441558441559
36	89.89254665374756	0.0	15.58441558441559
37	126.8941342830658	0.0	12.987012987012992
38	126.77502655982971	0.6993006993006978	16.883116883116877
39	103.94690799713135	0.0	15.58441558441559
17-12-08 16-32-39
epoch	training_time	train_perf	val_perf

0	134.38564801216125	43.70629370629371	37.66233766233766
1	133.88759636878967	43.70629370629371	37.66233766233766
2	126.25043392181396	43.70629370629371	37.66233766233766
3	134.95522570610046	43.70629370629371	37.66233766233766
4	133.223815202713	43.70629370629371	37.66233766233766
5	136.1258180141449	43.70629370629371	37.66233766233766
6	130.30398750305176	43.70629370629371	37.66233766233766
7	134.9647045135498	38.46153846153846	37.66233766233766
8	121.32493352890015	15.384615384615385	23.376623376623375
9	129.55656552314758	32.86713286713287	32.467532467532465
10	146.01771187782288	10.48951048951049	25.97402597402597
11	166.91424775123596	12.937062937062937	20.779220779220775
12	145.7039487361908	11.188811188811187	24.675324675324674
13	140.19970226287842	20.97902097902098	35.064935064935064
14	144.23405861854553	5.944055944055949	22.077922077922075
15	125.90747833251953	20.629370629370626	37.66233766233766
16	117.69924592971802	0.34965034965035446	14.28571428571429
17	118.72207999229431	0.6993006993006978	10.389610389610393
18	118.72127413749695	0.0	9.090909090909093
19	118.28015899658203	0.0	12.987012987012992
20	117.56789517402649	0.0	15.58441558441559
21	118.2676420211792	0.0	16.883116883116877
22	117.33449864387512	0.0	10.389610389610393
23	117.56996202468872	0.0	12.987012987012992
24	117.06915831565857	0.0	12.987012987012992
25	117.93690538406372	0.0	12.987012987012992
26	120.04152703285217	0.0	10.389610389610393
27	135.8706350326538	0.34965034965035446	16.883116883116877
28	134.7989547252655	0.0	14.28571428571429
29	165.09736585617065	0.0	11.688311688311693
30	142.22053980827332	0.0	10.389610389610393
31	142.00946378707886	0.0	10.389610389610393
32	143.82424116134644	0.0	10.389610389610393
33	157.27849221229553	0.0	10.389610389610393
34	147.34250330924988	0.0	10.389610389610393
35	133.6534788608551	0.0	11.688311688311693
36	141.38378047943115	2.0979020979020935	25.97402597402597
37	121.34234261512756	0.0	14.28571428571429
38	145.47853684425354	0.0	15.58441558441559
39	140.90041589736938	0.0	15.58441558441559
17-12-08 18-12-04
epoch	training_time	train_perf	val_perf

0	157.9349274635315	43.70629370629371	37.66233766233766
1	157.16301083564758	43.70629370629371	37.66233766233766
2	153.222177028656	43.70629370629371	37.66233766233766
3	153.14660739898682	43.70629370629371	37.66233766233766
4	149.09122037887573	43.70629370629371	37.66233766233766
5	148.9759156703949	43.70629370629371	37.66233766233766
6	149.73090648651123	43.70629370629371	37.66233766233766
7	149.13252186775208	43.70629370629371	37.66233766233766
8	148.97738599777222	8.391608391608397	23.376623376623375
9	148.82280492782593	31.46853146853147	32.467532467532465
10	149.29537677764893	40.90909090909091	36.36363636363637
11	148.61826181411743	6.99300699300699	19.480519480519476
12	149.66757678985596	13.636363636363635	23.376623376623375
13	148.42369508743286	4.545454545454541	16.883116883116877
14	214.16307091712952	4.545454545454541	20.779220779220775
15	179.31490898132324	1.0489510489510523	18.181818181818176
16	174.45109462738037	0.6993006993006978	14.28571428571429
17	167.3986804485321	0.0	22.077922077922075
18	177.48278331756592	0.0	16.883116883116877
19	178.13576340675354	0.0	19.480519480519476
20	212.33811473846436	0.0	20.779220779220775
21	192.03891134262085	0.0	12.987012987012992
22	184.32356595993042	0.0	23.376623376623375
23	164.63351130485535	0.0	22.077922077922075
24	184.9333474636078	0.0	16.883116883116877
25	196.88274788856506	0.0	15.58441558441559
26	184.51773476600647	0.0	18.181818181818176
27	197.1696560382843	0.0	16.883116883116877
28	217.9158594608307	0.0	23.376623376623375
29	191.6882894039154	0.0	19.480519480519476
30	187.93846440315247	0.0	18.181818181818176
31	183.63065314292908	0.0	20.779220779220775
32	174.7123727798462	0.0	20.779220779220775
33	188.70558285713196	0.0	16.883116883116877
34	213.68077898025513	0.0	18.181818181818176
35	171.46291399002075	0.0	20.779220779220775
36	188.8985936641693	0.0	20.779220779220775
37	212.48589515686035	0.0	20.779220779220775
38	216.33042883872986	0.0	23.376623376623375
39	218.2492172718048	0.0	19.480519480519476
17-12-08 20-18-33
epoch	training_time	train_perf	val_perf

0	239.1445803642273	43.70629370629371	37.66233766233766
1	292.7475881576538	43.70629370629371	37.66233766233766
2	290.7528839111328	43.70629370629371	37.66233766233766
3	229.39538717269897	43.70629370629371	37.66233766233766
4	208.99723267555237	43.70629370629371	37.66233766233766
5	238.8626160621643	43.70629370629371	37.66233766233766
6	222.77425289154053	43.70629370629371	37.66233766233766
7	223.70264720916748	41.95804195804196	37.66233766233766
8	225.6632068157196	38.11188811188811	35.064935064935064
9	205.94776225090027	34.61538461538461	33.76623376623377
10	201.29909658432007	18.881118881118887	31.16883116883117
11	210.43752694129944	22.72727272727273	33.76623376623377
12	194.55548095703125	2.7972027972028024	24.675324675324674
13	210.48242473602295	2.447552447552448	15.58441558441559
14	202.91608667373657	0.34965034965035446	15.58441558441559
15	215.70441722869873	7.692307692307687	23.376623376623375
16	211.81261825561523	0.0	14.28571428571429
17	221.47327756881714	0.0	15.58441558441559
18	207.40891075134277	0.0	18.181818181818176
19	206.08254313468933	0.0	16.883116883116877
20	196.54476690292358	0.0	15.58441558441559
21	192.5138659477234	0.0	16.883116883116877
22	201.76685214042664	0.0	14.28571428571429
23	207.66688108444214	0.0	18.181818181818176
24	209.34395170211792	0.0	18.181818181818176
25	216.27261328697205	0.0	19.480519480519476
26	218.0381486415863	0.0	14.28571428571429
27	215.86279463768005	0.0	16.883116883116877
28	222.20174622535706	0.0	19.480519480519476
29	208.02823996543884	0.0	16.883116883116877
30	213.55377507209778	0.0	18.181818181818176
31	234.55362796783447	0.0	18.181818181818176
32	204.42527890205383	0.0	19.480519480519476
33	212.7196397781372	0.0	18.181818181818176
34	221.7919545173645	0.0	18.181818181818176
35	243.58223462104797	0.0	18.181818181818176
36	193.84094738960266	0.0	15.58441558441559
37	194.082444190979	0.0	19.480519480519476
38	198.33100485801697	0.0	19.480519480519476
39	230.20165610313416	0.0	19.480519480519476

===============================================================================
17-12-08 23-03-12
epoch	training_time	train_perf	val_perf

0	49.541171073913574	43.70629370629371	37.66233766233766
1	48.7886757850647	43.70629370629371	37.66233766233766
2	51.31035375595093	43.70629370629371	37.66233766233766
3	52.6134934425354	43.70629370629371	37.66233766233766
4	50.85072636604309	43.70629370629371	37.66233766233766
5	49.46600937843323	43.70629370629371	37.66233766233766
6	50.70144248008728	43.70629370629371	37.66233766233766
7	46.491438150405884	43.70629370629371	37.66233766233766
8	46.35742902755737	43.70629370629371	37.66233766233766
9	51.89326238632202	43.70629370629371	37.66233766233766
10	50.289814949035645	40.55944055944056	37.66233766233766
11	54.007142066955566	15.73426573426573	23.376623376623375
12	45.1973295211792	16.78321678321678	23.376623376623375
13	45.45168614387512	14.685314685314687	33.76623376623377
14	48.9993360042572	4.1958041958041985	18.181818181818176
15	49.53429889678955	18.181818181818176	27.27272727272727
16	49.88024711608887	7.692307692307687	32.467532467532465
17	48.484355211257935	1.3986013986013957	16.883116883116877
18	47.87948989868164	2.0979020979020935	24.675324675324674
19	49.33434557914734	0.34965034965035446	16.883116883116877
20	57.47519588470459	0.34965034965035446	16.883116883116877
21	65.02280688285828	0.0	15.58441558441559
22	68.41495323181152	0.0	18.181818181818176
23	66.09118843078613	0.0	18.181818181818176
24	59.81632375717163	0.0	16.883116883116877
25	60.12155103683472	0.0	14.28571428571429
26	63.50765538215637	0.0	14.28571428571429
27	72.02673006057739	0.0	14.28571428571429
28	54.920844316482544	0.0	15.58441558441559
29	56.31893348693848	0.0	15.58441558441559
30	66.78407621383667	0.34965034965035446	29.87012987012987
31	69.03960680961609	0.0	12.987012987012992
32	52.23829913139343	0.0	16.883116883116877
33	49.71871566772461	0.0	14.28571428571429
34	53.48898983001709	0.0	15.58441558441559
35	56.427329301834106	0.0	14.28571428571429
36	54.243345975875854	0.0	14.28571428571429
37	56.0954270362854	0.0	16.883116883116877
38	58.80598282814026	0.0	15.58441558441559
39	65.56572437286377	0.0	18.181818181818176
17-12-08 23-44-10
epoch	training_time	train_perf	val_perf

0	58.690123319625854	43.70629370629371	37.66233766233766
1	55.60212731361389	43.70629370629371	37.66233766233766
2	64.06313753128052	43.70629370629371	37.66233766233766
3	62.34743547439575	43.70629370629371	37.66233766233766
4	59.59483575820923	43.70629370629371	37.66233766233766
5	58.546106576919556	43.70629370629371	37.66233766233766
6	58.99268341064453	43.70629370629371	37.66233766233766
7	58.66029071807861	43.70629370629371	37.66233766233766
8	65.19182562828064	41.95804195804196	37.66233766233766
9	70.89547109603882	40.55944055944056	37.66233766233766
10	73.96286630630493	43.006993006993014	37.66233766233766
11	56.8664608001709	13.636363636363635	27.27272727272727
12	63.95262050628662	5.24475524475524	18.181818181818176
13	65.96296525001526	6.643356643356646	19.480519480519476
14	70.04234743118286	3.4965034965035002	19.480519480519476
15	69.86478090286255	0.34965034965035446	23.376623376623375
16	85.30847930908203	2.0979020979020935	19.480519480519476
17	73.98500847816467	39.86013986013987	37.66233766233766
18	75.8702654838562	0.0	15.58441558441559
19	64.36245703697205	0.0	23.376623376623375
20	52.106035232543945	5.944055944055949	28.57142857142857
21	60.584431171417236	0.0	18.181818181818176
22	68.64372205734253	0.0	20.779220779220775
23	72.5597083568573	0.0	20.779220779220775
24	52.224608421325684	0.0	18.181818181818176
25	61.636157274246216	0.0	20.779220779220775
26	54.214280128479004	0.0	19.480519480519476
27	54.92338991165161	0.0	19.480519480519476
28	55.49540829658508	0.0	22.077922077922075
29	55.3819739818573	0.0	18.181818181818176
30	56.43265199661255	0.0	22.077922077922075
31	55.67306661605835	0.0	20.779220779220775
32	54.811906576156616	0.0	20.779220779220775
33	61.471590995788574	0.0	20.779220779220775
34	56.56114864349365	0.0	19.480519480519476
35	56.43605923652649	0.0	19.480519480519476
36	57.437771797180176	0.0	19.480519480519476
37	54.57673931121826	0.0	18.181818181818176
38	53.26681089401245	0.0	18.181818181818176
39	53.275816679000854	0.0	18.181818181818176
17-12-09 00-28-42
epoch	training_time	train_perf	val_perf

0	64.77137517929077	43.70629370629371	37.66233766233766
1	58.87252402305603	43.70629370629371	37.66233766233766
2	58.56673622131348	43.70629370629371	37.66233766233766
3	60.31410074234009	43.70629370629371	37.66233766233766
4	59.85321664810181	43.70629370629371	37.66233766233766
5	60.28574776649475	43.70629370629371	37.66233766233766
6	60.91709113121033	43.70629370629371	37.66233766233766
7	60.03233575820923	19.23076923076923	24.675324675324674
8	61.59329414367676	38.46153846153846	37.66233766233766
9	61.57167911529541	13.286713286713292	22.077922077922075
10	60.5569851398468	14.685314685314687	23.376623376623375
11	58.850773334503174	10.139860139860135	24.675324675324674
12	58.944841384887695	37.06293706293706	51.94805194805194
13	59.359135150909424	8.041958041958042	23.376623376623375
14	59.463207960128784	6.2937062937062915	23.376623376623375
15	59.468212366104126	2.0979020979020935	22.077922077922075
16	59.65234303474426	5.594405594405593	40.25974025974026
17	59.5362606048584	0.6993006993006978	22.077922077922075
18	59.27507519721985	0.34965034965035446	20.779220779220775
19	59.639333724975586	0.0	23.376623376623375
20	60.50492882728577	0.0	24.675324675324674
21	59.81860113143921	0.0	15.58441558441559
22	59.84648656845093	0.0	24.675324675324674
23	59.941542863845825	0.0	20.779220779220775
24	60.16870903968811	0.0	22.077922077922075
25	62.22316789627075	0.0	27.27272727272727
26	68.21845865249634	0.0	19.480519480519476
27	63.603904008865356	0.0	18.181818181818176
28	58.393699407577515	0.0	15.58441558441559
29	58.0582377910614	0.0	16.883116883116877
30	69.43462347984314	0.0	19.480519480519476
31	57.384467124938965	0.0	18.181818181818176
32	57.19031238555908	0.0	16.883116883116877
33	57.2186975479126	0.0	18.181818181818176
34	57.1998872756958	0.0	16.883116883116877
35	57.6252555847168	0.0	15.58441558441559
36	68.62110424041748	0.0	14.28571428571429
37	57.44498896598816	0.0	14.28571428571429
38	56.989243030548096	0.0	14.28571428571429
39	63.035926818847656	0.0	14.28571428571429
17-12-09 01-12-27
epoch	training_time	train_perf	val_perf

0	75.51979303359985	43.70629370629371	37.66233766233766
1	80.01482963562012	43.70629370629371	37.66233766233766
2	59.93466782569885	43.70629370629371	37.66233766233766
3	91.45198035240173	43.70629370629371	37.66233766233766
4	78.80159640312195	43.70629370629371	37.66233766233766
5	84.96830701828003	43.70629370629371	37.66233766233766
6	81.65652918815613	43.70629370629371	37.66233766233766
7	90.62981367111206	43.70629370629371	37.66233766233766
8	67.43613505363464	43.70629370629371	37.66233766233766
9	81.19240260124207	43.70629370629371	37.66233766233766
10	70.6414635181427	43.70629370629371	37.66233766233766
11	64.30659198760986	43.70629370629371	37.66233766233766
12	83.71414828300476	24.825174825174823	48.05194805194806
13	72.21783661842346	24.825174825174823	27.27272727272727
14	70.53497791290283	39.51048951048951	37.66233766233766
15	66.67766094207764	13.98601398601399	19.480519480519476
16	60.50418543815613	13.98601398601399	20.779220779220775
17	65.66097044944763	5.594405594405593	19.480519480519476
18	77.92662477493286	3.4965034965035002	20.779220779220775
19	87.87147426605225	6.643356643356646	29.87012987012987
20	81.82862997055054	0.6993006993006978	15.58441558441559
21	78.1657772064209	0.34965034965035446	22.077922077922075
22	80.94590163230896	13.98601398601399	28.57142857142857
23	71.61687135696411	0.34965034965035446	19.480519480519476
24	70.922922372818	0.34965034965035446	19.480519480519476
25	72.59941029548645	0.34965034965035446	14.28571428571429
26	81.31441116333008	0.34965034965035446	16.883116883116877
27	83.4336256980896	0.34965034965035446	16.883116883116877
28	81.30268788337708	0.0	16.883116883116877
29	77.13972234725952	0.0	16.883116883116877
30	82.28235912322998	0.0	14.28571428571429
31	83.13443541526794	0.0	14.28571428571429
32	63.607112646102905	0.0	18.181818181818176
33	56.64814758300781	0.0	14.28571428571429
34	80.49449348449707	0.0	15.58441558441559
35	78.71374845504761	0.0	14.28571428571429
36	63.231208086013794	0.0	14.28571428571429
37	64.59552121162415	0.0	14.28571428571429
38	63.064427852630615	0.0	12.987012987012992
39	60.35388803482056	0.0	14.28571428571429
17-12-09 02-05-39
epoch	training_time	train_perf	val_perf

0	67.01146483421326	43.70629370629371	37.66233766233766
1	71.55534195899963	43.70629370629371	37.66233766233766
2	67.56896305084229	43.70629370629371	37.66233766233766
3	60.24259161949158	43.70629370629371	37.66233766233766
4	60.13036823272705	43.70629370629371	37.66233766233766
5	63.82237458229065	43.70629370629371	37.66233766233766
6	75.07981991767883	43.70629370629371	37.66233766233766
7	59.55254316329956	43.70629370629371	37.66233766233766
8	60.03198957443237	43.70629370629371	37.66233766233766
9	59.50074028968811	43.70629370629371	37.66233766233766
10	59.84448981285095	43.70629370629371	37.66233766233766
11	60.21950149536133	14.685314685314687	38.961038961038966
12	59.65698552131653	41.25874125874126	37.66233766233766
13	59.87574243545532	28.671328671328666	51.94805194805194
14	59.51636362075806	12.23776223776224	18.181818181818176
15	58.81323289871216	9.790209790209792	19.480519480519476
16	59.21948480606079	10.139860139860135	20.779220779220775
17	58.90697884559631	31.818181818181824	32.467532467532465
18	59.094482421875	4.1958041958041985	18.181818181818176
19	59.03198027610779	24.125874125874127	50.64935064935065
20	59.14135813713074	4.895104895104896	20.779220779220775
21	59.481470346450806	9.440559440559436	27.27272727272727
22	59.110109090805054	2.0979020979020935	24.675324675324674
23	59.688236951828	0.0	22.077922077922075
24	59.063233613967896	0.0	15.58441558441559
25	59.09448194503784	0.0	18.181818181818176
26	59.20385980606079	0.0	16.883116883116877
27	59.23511290550232	0.0	19.480519480519476
28	59.39135980606079	0.0	19.480519480519476
29	59.37573456764221	0.0	15.58441558441559
30	59.500738859176636	0.0	18.181818181818176
31	59.485111713409424	0.0	18.181818181818176
32	59.43823719024658	0.0	18.181818181818176
33	59.43823766708374	0.0	19.480519480519476
34	59.516364336013794	0.0	24.675324675324674
35	59.39136028289795	0.0	15.58441558441559
36	59.28198599815369	0.0	16.883116883116877
37	60.31325054168701	0.0	16.883116883116877
38	59.75073719024658	0.0	20.779220779220775
39	59.71949005126953	0.0	16.883116883116877